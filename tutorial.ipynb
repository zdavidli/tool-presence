{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from src import endoscopy_dataset as eds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidli/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/davidli/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 37692.9141, KL Div: 2767.1160\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29855.2207, KL Div: 962.0600\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 27324.4980, KL Div: 1262.7107\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 26748.0488, KL Div: 563.6359\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 25346.4355, KL Div: 807.6569\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 25586.5117, KL Div: 682.6670\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 24657.2832, KL Div: 817.7370\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 23257.2285, KL Div: 1059.7998\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 23292.3496, KL Div: 1208.4426\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 22497.9922, KL Div: 1248.2378\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 22111.6934, KL Div: 1454.9152\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 20280.6270, KL Div: 1534.4426\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 20111.0625, KL Div: 1584.6542\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 19819.5352, KL Div: 1638.3663\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 18792.7422, KL Div: 1671.4443\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 18295.2852, KL Div: 1719.0109\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18612.6250, KL Div: 1709.8491\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 18957.9688, KL Div: 1864.7582\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 17744.4023, KL Div: 1830.8843\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 18427.7520, KL Div: 1848.6530\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 18634.3516, KL Div: 2023.7174\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 17471.4043, KL Div: 1947.0312\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 17165.8926, KL Div: 2043.1201\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 16588.8945, KL Div: 2147.6768\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 15837.7725, KL Div: 2087.9976\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 16273.5771, KL Div: 2126.4597\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 16760.8184, KL Div: 2133.2366\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 16667.8672, KL Div: 2107.5955\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 15716.6211, KL Div: 2304.0188\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15466.7461, KL Div: 2355.0164\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 15857.4668, KL Div: 2237.3430\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 15722.2754, KL Div: 2382.2402\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 16147.7852, KL Div: 2427.8899\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 15229.5986, KL Div: 2403.8667\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 14967.0986, KL Div: 2503.1392\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 14462.0586, KL Div: 2531.8105\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 15137.3643, KL Div: 2532.5164\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 14275.8584, KL Div: 2665.9941\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 14541.8652, KL Div: 2561.7178\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14143.3809, KL Div: 2516.1711\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 15003.0225, KL Div: 2390.9937\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 15139.1865, KL Div: 2627.7385\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 13665.9590, KL Div: 2527.0129\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 14195.1934, KL Div: 2459.5315\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 13739.2051, KL Div: 2651.4253\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 14376.2520, KL Div: 2636.1272\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 13737.4121, KL Div: 2564.0630\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 13187.5410, KL Div: 2855.6653\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 13839.1768, KL Div: 2591.2268\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 13022.9297, KL Div: 2754.5417\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 13802.6377, KL Div: 2738.1865\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 14159.7871, KL Div: 2696.9851\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 13374.6826, KL Div: 2903.5405\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 13541.4785, KL Div: 2682.2500\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 13252.9756, KL Div: 2807.2251\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 13019.0303, KL Div: 2737.1431\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 13537.0742, KL Div: 2688.8120\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 12687.9893, KL Div: 2792.2109\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 13423.1855, KL Div: 2808.7993\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 12877.5723, KL Div: 2872.0640\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 12464.5664, KL Div: 2848.5293\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 13290.8125, KL Div: 2902.8679\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 12889.8135, KL Div: 2852.9990\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 13492.4502, KL Div: 2797.5371\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 13102.6338, KL Div: 2820.0706\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 13545.7646, KL Div: 2884.9453\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 12715.6914, KL Div: 2830.6135\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 12273.7549, KL Div: 2832.9810\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12706.6338, KL Div: 2837.7576\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12128.5088, KL Div: 2929.7146\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 13017.6191, KL Div: 2893.6211\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12426.0518, KL Div: 2847.9941\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 12356.1260, KL Div: 2889.2815\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 11875.2852, KL Div: 2864.6160\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 12092.5918, KL Div: 3042.5522\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 12625.3154, KL Div: 3017.6030\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 12284.1348, KL Div: 3031.9729\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 11995.9561, KL Div: 2981.0835\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 12008.7471, KL Div: 3044.4026\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 12080.1875, KL Div: 3057.4949\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 12311.3496, KL Div: 2950.1199\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 11909.6953, KL Div: 2952.6880\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 12359.8232, KL Div: 2926.5288\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 12043.9248, KL Div: 2904.7471\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 12006.0283, KL Div: 3025.4919\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 12215.8389, KL Div: 2953.2310\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 11480.2012, KL Div: 2997.8022\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 12418.0615, KL Div: 2863.4844\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 12469.7285, KL Div: 3104.8643\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 12195.5479, KL Div: 2994.0085\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 11953.6455, KL Div: 3039.0925\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 12496.8096, KL Div: 3071.7891\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 12147.1455, KL Div: 3063.1799\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 11816.4385, KL Div: 3003.2703\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 11981.9053, KL Div: 2927.7434\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 11733.6074, KL Div: 3065.2100\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 11742.2588, KL Div: 3017.8904\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 11245.7295, KL Div: 2951.7832\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 11964.3115, KL Div: 2987.9858\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 11941.1279, KL Div: 3111.8845\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 11155.3486, KL Div: 2967.6267\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 11781.1494, KL Div: 3124.1953\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 12600.6338, KL Div: 3095.4705\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11705.7744, KL Div: 3069.1079\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 11428.1416, KL Div: 2970.1838\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11213.1182, KL Div: 2974.6953\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 12188.6953, KL Div: 3027.1140\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11862.6865, KL Div: 3247.7295\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 12024.6768, KL Div: 3031.4431\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 11842.8965, KL Div: 3189.0059\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 11258.7705, KL Div: 3003.8975\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11425.0850, KL Div: 2989.8574\n",
      "Epoch[3/15], Step [210/469], Reconst Loss: 11755.1992, KL Div: 3176.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/15], Step [220/469], Reconst Loss: 11487.4424, KL Div: 3037.8818\n",
      "Epoch[3/15], Step [230/469], Reconst Loss: 11077.5508, KL Div: 3113.7205\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11558.8877, KL Div: 3028.6580\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11570.1084, KL Div: 3093.3687\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 11236.6582, KL Div: 3071.7366\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 11880.8682, KL Div: 3115.8943\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11634.3174, KL Div: 3204.1902\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 11742.7344, KL Div: 3112.4277\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 12181.9062, KL Div: 3093.8462\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 10941.2676, KL Div: 3056.9504\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11029.7461, KL Div: 3070.5920\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11336.3770, KL Div: 3019.7419\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11099.5869, KL Div: 3138.3442\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 10946.5283, KL Div: 3065.3066\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 11140.3643, KL Div: 3018.1016\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 11411.1494, KL Div: 3112.8308\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 11646.3096, KL Div: 3129.6160\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11426.5293, KL Div: 3124.7405\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 11500.1875, KL Div: 3041.6550\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 11531.9170, KL Div: 3186.0342\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 11505.1094, KL Div: 3130.5557\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 11372.8662, KL Div: 3112.5164\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 11563.6650, KL Div: 3183.2034\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 11150.3311, KL Div: 3139.2705\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 11596.2139, KL Div: 3133.1333\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 11274.5850, KL Div: 3122.7583\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 11183.4697, KL Div: 3171.9773\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 11125.3398, KL Div: 3010.2388\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 11708.0430, KL Div: 3265.2891\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11016.2158, KL Div: 3180.0137\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 11579.3389, KL Div: 3160.4004\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 11534.3223, KL Div: 3063.9883\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 11061.4951, KL Div: 3075.2593\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 11100.7568, KL Div: 3142.3184\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 10982.5508, KL Div: 3073.3252\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 11104.6982, KL Div: 3226.3735\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 11223.6484, KL Div: 3109.2778\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 10801.5293, KL Div: 3054.5139\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 11017.8789, KL Div: 3162.9402\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 10957.4961, KL Div: 3250.3872\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 11382.2197, KL Div: 2896.8130\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 11251.0264, KL Div: 3273.4204\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 11041.8467, KL Div: 3085.6492\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 10995.8770, KL Div: 3171.9177\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 11149.3359, KL Div: 3194.6733\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 11546.1211, KL Div: 3169.6709\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 11299.0996, KL Div: 3274.6721\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 10979.4600, KL Div: 3113.4844\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 11432.9619, KL Div: 3025.2144\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 11097.2383, KL Div: 3189.2510\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 10764.4072, KL Div: 3052.2002\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 10968.5156, KL Div: 3189.8730\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 11327.2822, KL Div: 3233.1384\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 11113.6260, KL Div: 3073.6157\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 10815.4795, KL Div: 3218.5964\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 10968.2041, KL Div: 3088.7515\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 11167.4561, KL Div: 3041.7388\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 11276.8916, KL Div: 3139.4536\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 10933.6309, KL Div: 3153.8792\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 10647.6426, KL Div: 3080.7578\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 11313.7148, KL Div: 3173.3242\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 11154.7324, KL Div: 3245.3196\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 11245.1875, KL Div: 3149.7312\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 11098.5996, KL Div: 3256.8025\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 11803.9307, KL Div: 3143.8184\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 10904.8525, KL Div: 3194.7993\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 10554.4609, KL Div: 3163.7468\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 10793.1328, KL Div: 3146.4866\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 10789.6123, KL Div: 3169.7393\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 11286.4336, KL Div: 3234.7307\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 11311.7373, KL Div: 3210.6252\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 10468.8574, KL Div: 3188.7681\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 10981.8584, KL Div: 3153.1680\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 11382.4355, KL Div: 3345.2793\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 10930.7402, KL Div: 3144.8274\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 10801.6855, KL Div: 3238.8149\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 10721.0146, KL Div: 3172.0854\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 10742.6914, KL Div: 3244.3264\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 11293.9473, KL Div: 3105.4800\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 11058.0000, KL Div: 3127.2791\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 11621.4600, KL Div: 3170.1206\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 10959.5518, KL Div: 3156.5884\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 10867.5811, KL Div: 3160.8564\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 10670.4434, KL Div: 3160.5410\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 10978.6592, KL Div: 3123.4202\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 11022.2197, KL Div: 3104.5874\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 10618.5088, KL Div: 3282.7183\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 11240.1309, KL Div: 3200.2454\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 10780.5176, KL Div: 3212.0022\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 11050.5908, KL Div: 3183.7324\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10608.4639, KL Div: 3113.4639\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 11189.1250, KL Div: 3259.1885\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 11196.7588, KL Div: 3158.9971\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 11223.5459, KL Div: 3235.3359\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 11452.1592, KL Div: 3209.4834\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 10591.4170, KL Div: 3118.7534\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 10840.2568, KL Div: 3229.8381\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 11130.8906, KL Div: 3186.2788\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 11220.7285, KL Div: 3182.4758\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 10533.9658, KL Div: 3240.0259\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 10998.3867, KL Div: 3254.7910\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 10412.3389, KL Div: 3050.4849\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 10596.2432, KL Div: 3138.7131\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 10446.3760, KL Div: 3245.2908\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 11001.0879, KL Div: 3149.7913\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 10931.9102, KL Div: 3260.7388\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 10397.7119, KL Div: 3128.3188\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 10630.2119, KL Div: 3153.0322\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 10880.6855, KL Div: 3191.5510\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 10776.7852, KL Div: 3148.7739\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10873.5205, KL Div: 3300.7610\n",
      "Epoch[5/15], Step [410/469], Reconst Loss: 10778.3213, KL Div: 3096.5928\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 10572.4102, KL Div: 3133.3057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/15], Step [430/469], Reconst Loss: 10497.3320, KL Div: 3303.8848\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 10592.2451, KL Div: 3243.0835\n",
      "Epoch[5/15], Step [450/469], Reconst Loss: 11087.9404, KL Div: 3300.6440\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 11078.1211, KL Div: 3197.2654\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 10950.2002, KL Div: 3135.9534\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 10197.8086, KL Div: 3211.1685\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 10494.7119, KL Div: 3063.8423\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 10502.1191, KL Div: 3251.8030\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 11021.0498, KL Div: 3188.2473\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 11211.2979, KL Div: 3251.9937\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 10993.0117, KL Div: 3196.2568\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 11024.1914, KL Div: 3354.7925\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 10439.7930, KL Div: 3127.8145\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10942.5947, KL Div: 3309.4895\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 10956.2178, KL Div: 3197.8713\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 10416.9775, KL Div: 3104.3962\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 10619.1797, KL Div: 3234.4048\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10540.7871, KL Div: 3246.7356\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 11165.3115, KL Div: 3192.3850\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 11123.7969, KL Div: 3258.7234\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 10719.0771, KL Div: 3296.7769\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 11101.0068, KL Div: 3145.3818\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 10959.3262, KL Div: 3204.7952\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10597.2051, KL Div: 3083.6306\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 10743.0996, KL Div: 3307.8994\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 10562.1211, KL Div: 3078.3120\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 10863.0508, KL Div: 3192.8772\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10747.4893, KL Div: 3267.9868\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 11023.0039, KL Div: 3271.8152\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 10785.4053, KL Div: 3170.4543\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10628.3320, KL Div: 3268.7317\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 10751.2725, KL Div: 3229.1130\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 10749.0518, KL Div: 3122.9666\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10889.2285, KL Div: 3208.1016\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 11343.8779, KL Div: 3269.3228\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 10609.7617, KL Div: 3221.8484\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 11054.1797, KL Div: 3298.3804\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 11034.1016, KL Div: 3242.6724\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 10883.2686, KL Div: 3241.9458\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10271.4629, KL Div: 3166.7622\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 10247.4600, KL Div: 3238.9744\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10051.0742, KL Div: 3117.3594\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10651.3057, KL Div: 3267.6641\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10883.9941, KL Div: 3116.3713\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 10661.2061, KL Div: 3360.4482\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10393.6113, KL Div: 3190.7224\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 10764.9951, KL Div: 3223.9094\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 10315.1133, KL Div: 3269.4985\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 10363.6611, KL Div: 3193.3145\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 11024.2812, KL Div: 3137.6882\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 10563.3398, KL Div: 3180.7246\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10471.2666, KL Div: 3210.8289\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 10370.2031, KL Div: 3325.0437\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10646.8379, KL Div: 3283.4534\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 9995.8379, KL Div: 3101.4526\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 10068.6719, KL Div: 3140.8457\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10190.1152, KL Div: 3280.5732\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 10737.3408, KL Div: 3239.0608\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 10598.4756, KL Div: 3220.6560\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10622.8398, KL Div: 3211.1699\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 10661.2383, KL Div: 3161.2146\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 11044.1826, KL Div: 3346.6609\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10883.6426, KL Div: 3218.7422\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10682.6387, KL Div: 3341.4602\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10709.4961, KL Div: 3158.5417\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 10020.3975, KL Div: 3195.2017\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10473.0215, KL Div: 3170.3315\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 10437.0518, KL Div: 3057.9387\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 10510.4648, KL Div: 3258.8867\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10767.0068, KL Div: 3305.1523\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 10829.4414, KL Div: 3308.8059\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 10629.6025, KL Div: 3306.7944\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 10307.6084, KL Div: 3121.2849\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10631.3154, KL Div: 3296.7512\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 10589.3369, KL Div: 3138.1580\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 10656.8643, KL Div: 3324.0198\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10639.1924, KL Div: 3202.7119\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10359.8633, KL Div: 3173.6572\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 10292.1660, KL Div: 3207.8157\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10437.1367, KL Div: 3187.6907\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 10258.5273, KL Div: 3229.9705\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 10658.9072, KL Div: 3205.6143\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10438.3711, KL Div: 3228.2556\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10415.4854, KL Div: 3193.6309\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 10791.9639, KL Div: 3235.3855\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 10954.4951, KL Div: 3329.0166\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10437.4062, KL Div: 3168.0225\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 11173.3389, KL Div: 3216.2195\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10471.9502, KL Div: 3201.4800\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10434.4014, KL Div: 3218.6018\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10583.5020, KL Div: 3282.4504\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 10586.7861, KL Div: 3342.6946\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 10729.5078, KL Div: 3152.4729\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 9976.5449, KL Div: 3132.6838\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10133.9287, KL Div: 3279.1821\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10675.8838, KL Div: 3226.5671\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10322.5449, KL Div: 3260.2275\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10531.8730, KL Div: 3217.9526\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10534.2354, KL Div: 3301.6948\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10069.7793, KL Div: 3228.1921\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10700.0156, KL Div: 3178.5334\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10830.2773, KL Div: 3133.4250\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10086.4111, KL Div: 3237.5151\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10725.3398, KL Div: 3225.2461\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 10816.5146, KL Div: 3223.6086\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10458.1543, KL Div: 3231.8335\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10578.8389, KL Div: 3161.7429\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 10558.8984, KL Div: 3188.0405\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10562.0938, KL Div: 3218.9277\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 11014.0352, KL Div: 3271.1992\n",
      "Epoch[8/15], Step [150/469], Reconst Loss: 10667.9014, KL Div: 3288.8765\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10172.1582, KL Div: 3206.1672\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10466.6045, KL Div: 3250.3499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/15], Step [180/469], Reconst Loss: 10280.6338, KL Div: 3168.0024\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 10594.6689, KL Div: 3235.3335\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10321.8379, KL Div: 3241.3894\n",
      "Epoch[8/15], Step [210/469], Reconst Loss: 10038.1396, KL Div: 3245.3376\n",
      "Epoch[8/15], Step [220/469], Reconst Loss: 10611.2588, KL Div: 3170.0166\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10217.8887, KL Div: 3227.3948\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10076.3633, KL Div: 3298.5713\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 9861.5840, KL Div: 3091.7822\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10697.7285, KL Div: 3261.0850\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10588.4619, KL Div: 3167.0864\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10992.7588, KL Div: 3322.9292\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 10056.3506, KL Div: 3230.7893\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10630.6123, KL Div: 3185.7893\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 10659.3955, KL Div: 3257.4075\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10701.4023, KL Div: 3225.2209\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10303.7021, KL Div: 3177.6018\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 10475.0039, KL Div: 3193.4331\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 10710.0322, KL Div: 3299.3560\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10183.9258, KL Div: 3164.8511\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 10245.2324, KL Div: 3225.9133\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 11054.1748, KL Div: 3275.2573\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10347.3779, KL Div: 3137.4443\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10799.0830, KL Div: 3326.0286\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 10232.3857, KL Div: 3181.9553\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10705.4785, KL Div: 3225.3923\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10427.7363, KL Div: 3148.1357\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10617.9902, KL Div: 3318.9805\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 10959.1113, KL Div: 3249.3965\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10566.1582, KL Div: 3305.7971\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 10277.6660, KL Div: 3361.7866\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10811.2910, KL Div: 3166.3015\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10317.2539, KL Div: 3318.7119\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 10547.3682, KL Div: 3190.1995\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 10426.7266, KL Div: 3219.9409\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10551.3594, KL Div: 3322.1372\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10624.1592, KL Div: 3206.8755\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10108.9033, KL Div: 3248.6165\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 10196.4551, KL Div: 3211.1746\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10601.4346, KL Div: 3284.2942\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10067.5352, KL Div: 3112.3145\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10250.6182, KL Div: 3265.3972\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 10525.6299, KL Div: 3257.1824\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10543.5752, KL Div: 3158.2078\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 10416.8193, KL Div: 3300.2334\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10534.0391, KL Div: 3215.8013\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10528.6553, KL Div: 3278.5981\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 10560.7393, KL Div: 3170.7131\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10600.1943, KL Div: 3279.5559\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10149.1201, KL Div: 3195.9548\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10521.9004, KL Div: 3199.2051\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 10381.6816, KL Div: 3186.7256\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 10914.0488, KL Div: 3286.0823\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10383.8936, KL Div: 3121.6372\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10432.8760, KL Div: 3236.0396\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10746.5684, KL Div: 3181.3206\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 10544.2031, KL Div: 3167.1780\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10421.0654, KL Div: 3314.2334\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10324.6299, KL Div: 3292.4517\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10517.3350, KL Div: 3299.7063\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10487.7285, KL Div: 3156.8811\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10127.0430, KL Div: 3195.2634\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 10368.0127, KL Div: 3173.7732\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 10478.0928, KL Div: 3271.4316\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10526.7773, KL Div: 3340.1636\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10010.5684, KL Div: 3032.0559\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10592.7412, KL Div: 3289.4473\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 10447.7676, KL Div: 3138.1868\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 10388.8379, KL Div: 3309.8442\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10481.2324, KL Div: 3209.4802\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 10517.2871, KL Div: 3185.4941\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 10147.8838, KL Div: 3235.2109\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 10284.5146, KL Div: 3182.4055\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 9968.6123, KL Div: 3136.6575\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10028.0410, KL Div: 3188.3945\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10040.2109, KL Div: 3249.2209\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10041.0957, KL Div: 3254.2566\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 9933.3965, KL Div: 3268.2341\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 10107.4561, KL Div: 3149.6116\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 9689.9092, KL Div: 3200.3682\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10194.2539, KL Div: 3211.0237\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10363.4941, KL Div: 3221.6594\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 9968.2686, KL Div: 3148.2881\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 9889.0000, KL Div: 3137.5488\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 10378.5215, KL Div: 3260.9497\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10403.6631, KL Div: 3254.9377\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 10363.5635, KL Div: 3222.8528\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 9940.0283, KL Div: 3204.4192\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 10144.5010, KL Div: 3236.0042\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 10282.3516, KL Div: 3219.0566\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 10795.4990, KL Div: 3245.7581\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 10560.3262, KL Div: 3341.7463\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 10463.2871, KL Div: 3238.4976\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10662.9609, KL Div: 3297.6084\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 9878.5127, KL Div: 3137.9893\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10345.2393, KL Div: 3228.3320\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 10643.4492, KL Div: 3261.1562\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10189.3408, KL Div: 3230.9482\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10394.2529, KL Div: 3241.6821\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 10271.1289, KL Div: 3237.4805\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 10688.1504, KL Div: 3323.6035\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 10248.4951, KL Div: 3171.5925\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 10385.3086, KL Div: 3325.5854\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 10735.2666, KL Div: 3237.9009\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10657.8262, KL Div: 3291.7183\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10583.6172, KL Div: 3324.6995\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 10156.9238, KL Div: 3216.0173\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10276.6396, KL Div: 3260.6401\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 10131.5146, KL Div: 3121.7207\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10362.5410, KL Div: 3266.0981\n",
      "Epoch[10/15], Step [350/469], Reconst Loss: 10312.0205, KL Div: 3251.4585\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 10574.2236, KL Div: 3178.4531\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 10070.6992, KL Div: 3270.6777\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 10316.0811, KL Div: 3342.7732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/15], Step [390/469], Reconst Loss: 10050.2949, KL Div: 3196.6487\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 9742.0352, KL Div: 3146.4629\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 10419.1143, KL Div: 3213.1665\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10362.7207, KL Div: 3230.6592\n",
      "Epoch[10/15], Step [430/469], Reconst Loss: 10353.4297, KL Div: 3298.9927\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 10394.3516, KL Div: 3144.6262\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10021.2236, KL Div: 3171.1187\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 10222.4170, KL Div: 3312.0508\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 10459.4336, KL Div: 3255.2244\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 10205.6650, KL Div: 3284.2590\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 10447.6055, KL Div: 3221.4050\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 10285.7617, KL Div: 3181.1077\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10303.8125, KL Div: 3335.3320\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 10702.3770, KL Div: 3284.1450\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10352.5518, KL Div: 3237.4900\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 10376.6553, KL Div: 3276.3457\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 10198.6064, KL Div: 3167.8196\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10298.1045, KL Div: 3246.0588\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 10157.4160, KL Div: 3192.5454\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 10495.8057, KL Div: 3224.3862\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10417.9268, KL Div: 3203.3330\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 10422.0400, KL Div: 3296.2275\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 10235.1748, KL Div: 3258.4187\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 10352.5205, KL Div: 3346.7961\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10001.6250, KL Div: 3248.1509\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10806.9844, KL Div: 3281.5657\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 10139.3408, KL Div: 3379.9226\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 9772.1963, KL Div: 3124.8501\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10195.9062, KL Div: 3118.0718\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10049.7510, KL Div: 3313.3894\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 10396.1660, KL Div: 3235.5107\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10080.7510, KL Div: 3122.9600\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10290.8662, KL Div: 3134.9023\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 9858.7393, KL Div: 3167.3069\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 10625.5586, KL Div: 3302.9783\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 9857.6348, KL Div: 3175.3730\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 10809.5537, KL Div: 3300.1150\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 10203.6523, KL Div: 3337.6418\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 10498.4316, KL Div: 3249.4268\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 10227.1797, KL Div: 3319.0681\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 10137.8369, KL Div: 3225.7871\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 9418.4629, KL Div: 3230.6746\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 9870.3164, KL Div: 3135.7070\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 10109.1592, KL Div: 3211.3359\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 10751.5615, KL Div: 3360.5356\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 10433.0234, KL Div: 3197.3613\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 9829.7480, KL Div: 3179.6692\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 9901.6943, KL Div: 3213.4241\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 10397.1836, KL Div: 3300.2505\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10495.0547, KL Div: 3295.5371\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10570.7295, KL Div: 3363.0940\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 10602.9980, KL Div: 3273.1091\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 10681.4121, KL Div: 3321.3560\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 10060.6475, KL Div: 3282.1592\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 10320.0469, KL Div: 3280.9548\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 9949.6807, KL Div: 3302.8699\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 10204.4141, KL Div: 3248.4727\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 10407.6855, KL Div: 3278.4116\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 10085.9131, KL Div: 3176.2939\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 9995.5977, KL Div: 3263.6824\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 10150.3594, KL Div: 3255.9060\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 10289.6182, KL Div: 3209.5400\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 10655.7090, KL Div: 3249.3169\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10686.0742, KL Div: 3262.5654\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 10226.9189, KL Div: 3257.0374\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 9980.0918, KL Div: 3216.6792\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 10315.2109, KL Div: 3323.4163\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 10315.5781, KL Div: 3256.7078\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 9739.8516, KL Div: 3174.9160\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 10533.0547, KL Div: 3304.7126\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10099.1104, KL Div: 3265.8726\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10214.3291, KL Div: 3349.0232\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10174.9883, KL Div: 3244.2151\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 10289.2676, KL Div: 3161.8123\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 10192.6377, KL Div: 3277.8464\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 9863.2578, KL Div: 3091.9988\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 10177.7402, KL Div: 3298.5693\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 10044.1514, KL Div: 3249.3716\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 9777.6006, KL Div: 3225.9619\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10178.4990, KL Div: 3235.6760\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 10179.0361, KL Div: 3283.4768\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 11041.8896, KL Div: 3341.6025\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 10206.3486, KL Div: 3282.5718\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10089.5605, KL Div: 3208.4751\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 9867.9541, KL Div: 3303.8403\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 10147.9609, KL Div: 3221.9475\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 10021.5684, KL Div: 3274.6423\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 10092.1523, KL Div: 3318.8345\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 9652.2021, KL Div: 3154.5000\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 10436.2842, KL Div: 3307.0984\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 10313.8105, KL Div: 3277.6440\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 10429.0176, KL Div: 3283.0374\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 10115.8008, KL Div: 3171.2468\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10288.4629, KL Div: 3336.3228\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 10423.2559, KL Div: 3248.2585\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 10343.0781, KL Div: 3217.6543\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 10614.1201, KL Div: 3299.2153\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10593.7676, KL Div: 3198.8091\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 10095.4658, KL Div: 3115.7893\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 10692.7236, KL Div: 3397.5747\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 9996.0469, KL Div: 3262.9915\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 10493.2393, KL Div: 3344.4062\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10568.4941, KL Div: 3196.2717\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 10003.3301, KL Div: 3285.4019\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 10228.3877, KL Div: 3176.1787\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 9793.4873, KL Div: 3251.8718\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 10282.1719, KL Div: 3302.6074\n",
      "Epoch[13/15], Step [80/469], Reconst Loss: 10298.9492, KL Div: 3352.0376\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 10269.6475, KL Div: 3357.0640\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10218.0107, KL Div: 3202.3088\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10248.3018, KL Div: 3172.3738\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10586.1152, KL Div: 3335.5295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/15], Step [130/469], Reconst Loss: 10543.1680, KL Div: 3269.5938\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 10077.0557, KL Div: 3173.3977\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 9854.2686, KL Div: 3248.2683\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 10054.8955, KL Div: 3207.6335\n",
      "Epoch[13/15], Step [170/469], Reconst Loss: 10240.9062, KL Div: 3316.2998\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 10487.6055, KL Div: 3324.5659\n",
      "Epoch[13/15], Step [190/469], Reconst Loss: 10217.6445, KL Div: 3183.8440\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10211.7363, KL Div: 3275.9092\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 10536.0977, KL Div: 3352.8062\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 10083.1611, KL Div: 3141.8953\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10242.8418, KL Div: 3342.1204\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 9618.8008, KL Div: 3195.4709\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10183.7158, KL Div: 3333.6194\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 10275.7197, KL Div: 3334.8306\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 10158.9766, KL Div: 3160.1299\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 10158.0498, KL Div: 3176.0762\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10158.2705, KL Div: 3225.8362\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 9970.1064, KL Div: 3201.9214\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 10401.2695, KL Div: 3350.1484\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10256.9268, KL Div: 3285.3391\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10641.0830, KL Div: 3350.3425\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 10474.3936, KL Div: 3339.3669\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 10929.0869, KL Div: 3290.7490\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 10551.4209, KL Div: 3263.8218\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 10625.4893, KL Div: 3269.8044\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 10875.8057, KL Div: 3456.6672\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10305.2764, KL Div: 3276.7285\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 10639.1426, KL Div: 3310.7871\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 10258.2666, KL Div: 3284.6389\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 9709.0469, KL Div: 3225.1025\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10505.1992, KL Div: 3305.5845\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10467.8955, KL Div: 3313.1057\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 9991.3730, KL Div: 3156.6267\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 10232.0176, KL Div: 3267.8308\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 10140.9424, KL Div: 3264.3860\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 10217.4531, KL Div: 3325.7625\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10242.0254, KL Div: 3175.6760\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10119.9189, KL Div: 3348.1450\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 9709.1689, KL Div: 3174.7676\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 10049.3535, KL Div: 3196.4231\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 10433.0420, KL Div: 3309.3203\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 10179.9717, KL Div: 3245.6733\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 10263.2744, KL Div: 3357.5234\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 9963.9521, KL Div: 3233.8955\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 10487.3047, KL Div: 3243.1145\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10098.1807, KL Div: 3322.9377\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 10331.0762, KL Div: 3348.7446\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 10331.7363, KL Div: 3222.1511\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 10606.6758, KL Div: 3355.8987\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 10732.1973, KL Div: 3381.9348\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 10208.2373, KL Div: 3124.7183\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 10248.6270, KL Div: 3370.1516\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 10233.0322, KL Div: 3174.1858\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 10144.3584, KL Div: 3117.1924\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 9616.7119, KL Div: 3232.5601\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 10307.4570, KL Div: 3201.6968\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 10196.8770, KL Div: 3178.4910\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 10315.9922, KL Div: 3329.3582\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 10355.7930, KL Div: 3051.0227\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 10547.6309, KL Div: 3360.6289\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 10468.5752, KL Div: 3303.2209\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 9997.4150, KL Div: 3259.9849\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 9983.1133, KL Div: 3257.6904\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 9858.5703, KL Div: 3147.4385\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 9993.6475, KL Div: 3233.9355\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 9892.5420, KL Div: 3198.3018\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 10042.2881, KL Div: 3226.8755\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 10432.6328, KL Div: 3256.3491\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 10327.0029, KL Div: 3337.9609\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 10178.3652, KL Div: 3228.8523\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 10396.6631, KL Div: 3419.7239\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 10186.8135, KL Div: 3341.2280\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 10299.7178, KL Div: 3195.2183\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10034.3975, KL Div: 3244.2717\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 9825.1719, KL Div: 3336.1021\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 10035.9688, KL Div: 3171.9011\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 10072.2578, KL Div: 3208.3792\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 10237.9307, KL Div: 3271.6411\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 10468.1514, KL Div: 3278.5476\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 9952.4971, KL Div: 3268.4641\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 9914.7656, KL Div: 3335.5515\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 9929.3770, KL Div: 3189.0894\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 9996.3340, KL Div: 3117.4033\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 10134.2656, KL Div: 3291.6719\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 10366.8066, KL Div: 3256.5242\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 10212.9297, KL Div: 3255.7920\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 10185.1201, KL Div: 3326.8491\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10486.6172, KL Div: 3316.2012\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 9975.9932, KL Div: 3217.7361\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 9917.1123, KL Div: 3226.2351\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 10292.2705, KL Div: 3278.1990\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 9742.5146, KL Div: 3240.1760\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 9870.9668, KL Div: 3274.6802\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 10212.7080, KL Div: 3331.4211\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 10255.6006, KL Div: 3231.6375\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 10377.7178, KL Div: 3250.3372\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 10380.6230, KL Div: 3285.2156\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 10234.1357, KL Div: 3226.4717\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 10542.8525, KL Div: 3366.8535\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 10006.1006, KL Div: 3117.4111\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 10426.7744, KL Div: 3363.4524\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 10110.1172, KL Div: 3308.0679\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 10443.5029, KL Div: 3254.3940\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 9929.7344, KL Div: 3234.1790\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 10117.9492, KL Div: 3255.9546\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 10322.7217, KL Div: 3217.0190\n",
      "Epoch[15/15], Step [270/469], Reconst Loss: 9911.5859, KL Div: 3335.9338\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 10120.1006, KL Div: 3265.5369\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 10441.5225, KL Div: 3264.7385\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 10499.8203, KL Div: 3248.3711\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 10062.4473, KL Div: 3249.8257\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 9725.5010, KL Div: 3186.7976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/15], Step [330/469], Reconst Loss: 9743.1592, KL Div: 3234.6709\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 9853.9326, KL Div: 3341.8723\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 10666.9668, KL Div: 3265.5151\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 10826.6543, KL Div: 3249.6184\n",
      "Epoch[15/15], Step [370/469], Reconst Loss: 10045.8457, KL Div: 3227.9663\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 9973.5605, KL Div: 3232.0972\n",
      "Epoch[15/15], Step [390/469], Reconst Loss: 9751.1934, KL Div: 3097.3025\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10222.9561, KL Div: 3228.5718\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 10291.0107, KL Div: 3222.7703\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 10192.0176, KL Div: 3132.4578\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 10526.6934, KL Div: 3273.9268\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 9557.6348, KL Div: 3149.6729\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 10111.1816, KL Div: 3234.9231\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 10442.7930, KL Div: 3299.7493\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a directory if not exists\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# MNIST dataset\n",
    "# dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "#                                      train=True,\n",
    "#                                      transform=transforms.ToTensor(),\n",
    "#                                      download=True)\n",
    "\n",
    "\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n",
    "\n",
    "\n",
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
