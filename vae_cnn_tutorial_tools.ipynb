{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial \n",
    "\n",
    "Based off: https://github.com/sksq96/pytorch-vae/blob/master/vae-cnn.ipynb\n",
    "\n",
    "Data used: Sinus Endoscopy Video from https://www.youtube.com/watch?v=6niL7Poc_qQ\n",
    "\n",
    "Simplifying Decisions:\n",
    "\n",
    "* Downscale image to 64x64 with center crop (not perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "batch_size=32\n",
    "epochs = 50\n",
    "image_channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder('data/',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.Resize(32),\n",
    "                                               transforms.CenterCrop(32),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1576"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image here using matplotlib.\n",
    "def plot_image(tensor):\n",
    "    plt.figure()\n",
    "    # imshow needs a numpy array with the channel dimension\n",
    "    # as the the last dimension so we have to transpose things.\n",
    "    plt.imshow(tensor.numpy().transpose(1, 2, 0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_x, _ = dataset[0]\n",
    "plot_image(fixed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=32*32, z_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size())\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_channels = fixed_x.size(0)\n",
    "image_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (7): ReLU()\n",
       "    (8): Flatten()\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1024, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): UnFlatten()\n",
       "    (1): ConvTranspose2d(1024, 128, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): ConvTranspose2d(64, 32, kernel_size=(6, 6), stride=(2, 2))\n",
       "    (6): ReLU()\n",
       "    (7): ConvTranspose2d(32, 3, kernel_size=(6, 6), stride=(2, 2))\n",
       "    (8): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "std::exception",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f0ea6b1d63cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#         images = images.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mrecon_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-1bc9d4c80fc7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-1bc9d4c80fc7>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/research/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: std::exception"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    for idx, (images, _) in enumerate(data_loader):\n",
    "#         images = images.to(device)\n",
    "        recon_images, mu, logvar = model(images)\n",
    "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        to_print = \"Epoch[{}/{}] Loss: {:.3f} {:.3f} {:.3f}\".format(epoch+1, \n",
    "                                                                    epochs, \n",
    "                                                                    loss.item()/batch_size, \n",
    "                                                                    bce.item()/batch_size, \n",
    "                                                                    kld.item()/batch_size)\n",
    "        tqdm.write(to_print)\n",
    "        \n",
    "torch.save(model.state_dict(), 'vae.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_x = dataset[np.random.randint(1, 100)][0].unsqueeze(0)\n",
    "fixed_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recon_x = model(fixed_x)[0].squeeze()\n",
    "recon_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = torch.cat([fixed_x.squeeze(), recon_x], dim=2)\n",
    "compare.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(compare.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
