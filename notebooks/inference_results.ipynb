{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 22}\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('/users/dli44/tool-presence'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src import constants as c\n",
    "from src import utils\n",
    "from src import visualization as v\n",
    "from src import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "\n",
    "def get_inference_results(result, test_labels, metric=None, **kwargs):\n",
    "    posteriors = np.zeros((len(test_labels), 2))\n",
    "    predictions = np.zeros((len(test_labels), ))\n",
    "    for i, row in enumerate(test_labels.itertuples()):\n",
    "        logpz = np.log(np.mean(result['theta'][:], axis=0))  # mixing probabilities\n",
    "#         print(logpz.shape)\n",
    "        logpy_z0 = norm.logpdf(row[:len(test_labels.columns)-2],\n",
    "                               loc=np.mean(result['mu'][:,0]),\n",
    "                               scale=np.mean(result['sigma'][:,0]))\n",
    "        logpy_z1 = norm.logpdf(row[:len(test_labels.columns)-2],\n",
    "                               loc=np.mean(result['mu'][:,1]),\n",
    "                               scale=np.mean(result['sigma'][:,1]))\n",
    "        posterior0 = logpz[:, 0] + logpy_z0\n",
    "        posterior1 = logpz[:, 1] + logpy_z1\n",
    "#         print(logsumexp(posterior0), logsumexp(posterior1))\n",
    "        posteriors[i] = np.array([logsumexp(posterior0), logsumexp(posterior1)])\n",
    "        predictions[i] = int(logsumexp(posterior0) < logsumexp(posterior1))\n",
    "\n",
    "#     return posteriors\n",
    "    return metric(test_labels['Tool'].values, predictions, **kwargs)\n",
    "\n",
    "\n",
    "def inference_prediction(result, test_labels, metric=None, **kwargs):\n",
    "    posteriors = np.zeros((len(test_labels), 2))\n",
    "    predictions = np.zeros((len(test_labels), ))\n",
    "    for i, row in enumerate(test_labels.itertuples()):\n",
    "        logpz = np.log(np.mean(result['theta'][:], axis=0))  # mixing probabilities\n",
    "        logpy_z0 = norm.logpdf(row[:len(test_labels.columns)-2],\n",
    "                               loc=np.mean(result['mu'][:,0]),\n",
    "                               scale=np.mean(result['sigma'][:,0]))\n",
    "        logpy_z1 = norm.logpdf(row[:len(test_labels.columns)-2],\n",
    "                               loc=np.mean(result['mu'][:,1]),\n",
    "                               scale=np.mean(result['sigma'][:,1]))\n",
    "        posterior0 = logpz[:, 0] + logpy_z0\n",
    "        posterior1 = logpz[:, 1] + logpy_z1\n",
    "        posteriors[i] = np.array([logsumexp(posterior0), logsumexp(posterior1)])\n",
    "        predictions[i] = int(logsumexp(posterior0) < logsumexp(posterior1))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/users/dli44/tool-presence/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_dir = os.path.join(root, \"mmd_no_sigmoid\", \"fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(os.path.join(root, 'mmd_no_sigmoid', 'model.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "test = pd.read_csv(os.path.join(root, 'mmd_no_sigmoid/csv', 'beta_5.0_zdim_20_test.csv'), index_col=0)\n",
    "test_labels=os.path.join(root, \"data/youtube_data/val/labels.csv\")\n",
    "test_labels = pd.read_csv(test_labels, index_col=0)\n",
    "test_labels = pd.concat([test, test_labels], axis=1).dropna()\n",
    "fit = pickle.load(open(os.path.join(fits_dir, \"beta_5.0_zdim_20_nuts_fit.pkl\"), 'rb'))\n",
    "\n",
    "result = fit.extract()\n",
    "\n",
    "inf_results = get_inference_results(result, test_labels, metric=metrics.average_precision_score)\n",
    "print(inf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "fig.subplots_adjust(hspace=.3)\n",
    "\n",
    "ax[0].hist(result['mu'][:,0].flatten(), bins=100, label='Cluster 1', fc=[0,0,1,.5]);\n",
    "ax[0].hist(result['mu'][:,1].flatten(), bins=100, label='Cluster 2', fc=[1,0,0,.5]);\n",
    "ax[0].set_title(r\"$\\mu_1, \\mu_2$ vs Frequency\");\n",
    "ax[0].set_xlabel(r\"$\\mu$\");\n",
    "ax[0].set_ylabel(\"Frequency\");\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(result['sigma'][:,0].flatten(), bins=100, label='Cluster 1', fc=[0,0,1,.5]);\n",
    "ax[1].hist(result['sigma'][:,1].flatten(), bins=100, label='Cluster 2', fc=[1,0,0,.5]);\n",
    "ax[1].set_title(r\"$\\sigma_1, \\sigma_2$ vs Frequency\");\n",
    "ax[1].set_xlabel(r\"$\\sigma$\");\n",
    "ax[1].set_ylabel(\"Frequency\");\n",
    "ax[1].legend()\n",
    "# \n",
    "plt.savefig(\"learned_params_beta_5_zdim_20.pdf\", dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(result['mu'], axis=0)\n",
    "variances = np.square(np.mean(result['sigma'], axis=0))\n",
    "means, variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "for i in range(2):\n",
    "    mu, sigma = result['mu'][:,i], result['sigma'][:,i]\n",
    "    mu_ci = stats.t.interval(0.95, len(mu)-1, loc=np.mean(mu), scale=stats.sem(mu))\n",
    "    sigma_ci = stats.t.interval(0.95, len(sigma)-1, loc=np.mean(sigma), scale=stats.sem(sigma))\n",
    "    print(\"$\\hat{{\\mu}}_{{Z_{}}}$\\t: 95% confidence interval is [{:.4f}, {:.4f}]\".format(i, *mu_ci))\n",
    "    print(\"$\\hat{{\\sigma}}_{{Z_{}}}$\\t: 95% confidence interval is [{:.4f}, {:.4f}]\".format(i, *sigma_ci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(posteriors[:,1], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = {}\n",
    "\n",
    "for f in os.listdir(fits_dir):\n",
    "    if f.endswith(\"_fit.pkl\"):\n",
    "        params = f.split(\"_\")[:4]\n",
    "        data_name = \"_\".join(params)\n",
    "        l,z = int(float(params[1])), int(params[3])\n",
    "#         if z != 80: continue\n",
    "        if z not in history:\n",
    "            history[z] = {}\n",
    "    \n",
    "        test = pd.read_csv(os.path.join(root, 'mmd_no_sigmoid/csv', data_name + '_test.csv'), index_col=0)\n",
    "        test_labels=os.path.join(root, \"data/youtube_data/val/labels.csv\")\n",
    "        test_labels = pd.read_csv(test_labels, index_col=0)\n",
    "        test_labels = pd.concat([test, test_labels], axis=1).dropna()\n",
    "        fit = pickle.load(open(os.path.join(fits_dir, f), 'rb'))\n",
    "        if 'nuts' in f:\n",
    "#             continue\n",
    "            result = fit.extract()\n",
    "        else:\n",
    "            continue\n",
    "#             result = utils.pystan_vb_extract(fit)\n",
    "            \n",
    "        print(f,l,z)\n",
    "        inf_results = get_inference_results(result, test_labels, metric=metrics.precision_recall_fscore_support, average='binary')\n",
    "        history[z][l] = inf_results\n",
    "        precision, recall, fscore, support = inf_results\n",
    "        print(precision, recall, fscore, support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
